import time
from scrapers.ifyoucould import fetch_ifyoucould_jobs
from scrapers.unjobs import fetch_unjobs
from scrapers.workable import fetch_workable_jobs
from fetch_store.store_jobs import store_jobs  # ‚úÖ Calls `store_jobs.py`

# ‚úÖ Fetch Jobs from Scrapers
def fetch_jobs():
    """Fetch job listings from all sources and return as a dictionary."""
    print("\n‚è≥ Running job scrapers...")

    jobs = {
        "ifyoucould": fetch_ifyoucould_jobs(),
        "unjobs": fetch_unjobs(),
        "workable": fetch_workable_jobs(),
    }

    return jobs  # ‚úÖ Keeps jobs in separate lists by source

# ‚úÖ Main Function: Run Scrapers Every 3 Hours
def run_scrapers():
    while True:
        jobs = fetch_jobs()

        # ‚úÖ Send to Firestore via `store_jobs.py`
        if any(jobs.values()):  # ‚úÖ Checks if any list has jobs
            total_jobs = sum(len(v) for v in jobs.values())
            print(f"\nüíæ Sending {total_jobs} jobs to Firestore...")
            store_jobs(jobs)  # ‚úÖ Calls `store_jobs.py`
        else:
            print("\n‚ùå No jobs found across all sources.")

        # ‚è≥ Wait for 3 hours before running again
        print("\n‚è≥ Sleeping for 3 hours before the next run...\n")
        time.sleep(3 * 60 * 60)  # 3 hours in seconds

# ‚úÖ Run Scrapers
if __name__ == "__main__":
    run_scrapers()