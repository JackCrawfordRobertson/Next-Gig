import sys
import os
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))  # Go up one level
import config  # Import the config file

BASE_URL = "https://www.ifyoucouldjobs.com/jobs"
MAX_PAGES = 2  # Only scrape 2 pages

def fetch_ifyoucould_jobs():
    """Scrapes job listings from If You Could Jobs using Selenium with strict keyword filtering"""
    print("üîç Starting If You Could Jobs Scraper...")

    # Set up Chrome options
    options = Options()
    # REMOVE HEADLESS MODE FOR DEBUGGING
    options.add_argument("--headless")  # Run in background
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    print("üöÄ Launching Chrome Browser...")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    jobs = []

    for page in range(1, MAX_PAGES + 1):
        url = f"{BASE_URL}?page={page}"
        print(f"üåç Navigating to {url} (Page {page})")
        driver.get(url)
        time.sleep(5)  # Wait for page to load

        # ‚úÖ Handle Cookie Popup Only Once
        if page == 1:
            try:
                print("üç™ Checking for cookie popup...")
                cookie_button = driver.find_element(By.ID, "CybotCookiebotDialogBodyLevelButtonLevelOptinAllowAll")
                cookie_button.click()
                print("‚úÖ Cookie popup dismissed!")
                time.sleep(2)  # Wait after clicking
            except Exception:
                print("‚ö†Ô∏è No cookie popup found or already dismissed.")

        print("üîç Searching for job elements...")
        job_elements = driver.find_elements(By.CSS_SELECTOR, "article.bg-warm-grey, article.bg-light-peach")
        print(f"üìå Found {len(job_elements)} job elements on Page {page}.")

        for job in job_elements:
            try:
                # ‚úÖ Check if title exists, otherwise skip
                title_element = job.find_elements(By.CSS_SELECTOR, "h2.type-style-3")
                if title_element:
                    title = title_element[0].text.strip()
                else:
                    print("‚ö†Ô∏è Skipping job due to missing title")
                    continue

                company_element = job.find_elements(By.CSS_SELECTOR, "h3.type-style-4")
                company = company_element[0].text.strip() if company_element else "Unknown"

                location_element = job.find_elements(By.XPATH, ".//dt[contains(text(), 'Location')]/following-sibling::dd")
                location = location_element[0].text.strip() if location_element else "Unknown"

                salary_element = job.find_elements(By.XPATH, ".//dt[contains(text(), 'Salary')]/following-sibling::dd")
                salary = salary_element[0].text.strip() if salary_element else "Not listed"

                # ‚úÖ Fix: Get Full Job Link
                link_element = job.find_element(By.CSS_SELECTOR, "a.link-reset")
                relative_link = link_element.get_attribute("href")
                full_link = f"https://www.ifyoucouldjobs.com{relative_link}" if relative_link.startswith("/") else relative_link

                # ‚úÖ Strict Filtering: Only include jobs with an **exact match** in JOB_KEYWORDS
                if any(keyword.lower() == title.lower() for keyword in config.JOB_KEYWORDS):
                    print(f"üÜï Job Matched: {title} at {company} ({location}) - {salary}")
                    print(f"üîó Job Link: {full_link}")

                    jobs.append({
                        "title": title,
                        "company": company,
                        "location": location,
                        "salary": salary,
                        "url": full_link  # ‚úÖ Stores the full job URL
                    })
                else:
                    print(f"‚ùå Job Skipped: {title} (Does not match exact keywords)")

            except Exception as e:
                print(f"‚ö†Ô∏è Skipping a job due to error: {e}")
                continue  # Skip if any element is missing

    # input("üîç Press Enter to close the browser...")  # Keeps browser open for debugging
    driver.quit()
    print(f"‚úÖ Finished scraping. Total jobs found: {len(jobs)}")
    return jobs

# Run Scraper for Debugging
fetch_ifyoucould_jobs()